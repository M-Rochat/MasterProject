{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08606be-2202-4a3c-a474-66fbf17cd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, pipeline\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "from torch import cuda\n",
    "import numpy as np\n",
    "from datasets import load_dataset, DownloadMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67b57d-bf79-4b44-97c6-c3c4a8ec910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--seed\", default=42)\n",
    "parser.add_argument(\"--model_name\", default='facebook/bart-base')\n",
    "parser.add_argument(\"--dataset_dir\", default=\"modified_dataset/\")\n",
    "parser.add_argument(\"--reset_cache\", action='store_true')\n",
    "parser.add_argument(\"--device\", default='cuda' if cuda.is_available() else 'cpu')\n",
    "parser.add_argument(\"--output_dir\", default=\"./seq_to_seq\", help=\"The output directory\")\n",
    "parser.add_argument(\"--overwrite_output_dir\", default=True, help=\" overwrite the content of the output directory\")\n",
    "parser.add_argument(\"--num_train_epochs\", default=3)  # number of training epochs\n",
    "parser.add_argument(\"--per_device_train_batch_size\", default=32)  # batch size for training\n",
    "parser.add_argument(\"--per_device_eval_batch_size\", default=64)  # batch size for evaluation\n",
    "parser.add_argument(\"--eval_steps\", default=400)  # Number of update steps between two evaluations.\n",
    "parser.add_argument(\"--save_steps\", default=800)  # after # steps model is saved\n",
    "parser.add_argument(\"--warmup_steps\", default=500)  # number of warmup steps for learning rate scheduler\n",
    "parser.add_argument(\"--prediction_loss_only\", default=True)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44253620-4177-469f-a4fd-030301aaf041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 gpt_finetune.py parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7360bd-3306-4ffc-a62f-34b741893e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python gpt_finetune.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --output_dir /tmp/test-clm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9538075-43e3-4731-8bb8-2421d1ee3c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 gpt_finetune.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace901b7-0a1b-45a0-b18f-26f8edc2c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "\n",
    "model_name_or_path=\"./tmp/test-clm/checkpoint-1000\"\n",
    "#model_name_or_path='gpt2'\n",
    "device='cuda'\n",
    "set_seed(10)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "input_ids = tokenizer.encode(\"Answer this question: Of which color is the black horse? The color of the horse is\", return_tensors=\"pt\")\n",
    "generations = model.generate(input_ids=input_ids.to(device), do_sample=True, num_return_sequences=1, max_new_tokens=100)\n",
    "for gen in generations:\n",
    "    new_text = tokenizer.decode(gen)\n",
    "    print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa8a2c-5da5-4fea-99a3-86f9221f2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 gpt_finetune.py parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b2a8b-c748-4080-9f7d-660618c449f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
