{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31d30e3-fe77-4e48-8f13-a514c27349b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccfdbd-9015-405c-b209-4aa4eca5bca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c497dc31-ff49-4f21-ac90-8a1e5c48219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from script.dataset_utils import cleanup, triplet_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dcfcb0a-127b-4213-9780-530213cedf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir='dataset/'\n",
    "clean_dataset_dir = 'clean_dataset/'\n",
    "modified_dataset_dir = 'modified_dataset/'\n",
    "for data_dir in (dataset_dir,clean_dataset_dir,modified_dataset_dir):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "splits= ('train', 'test', 'dev')\n",
    "relations = {'Physical': ['ObjectUse', 'CapableOf', 'MadeUpOf', 'HasProperty', 'Desires', 'NotDesires',\n",
    "                                           'AtLocation'],\n",
    "                     'Event': ['Causes', 'HinderedBy', 'xReason', 'isAfter', 'isBefore', 'HasSubEvent',\n",
    "                                        'isFilledBy'],\n",
    "                     'Intent': ['xIntent', 'xNeed', 'xWant', 'oWant'],\n",
    "             'Reaction': ['xReact', 'oReact', 'xAttr', 'xEffect','oEffect']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c3cb3-53c1-46a4-b615-a644e202effb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## make clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f71bc4-282b-49a6-adb5-267ddb020b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old size (1076880, 3), after removing None new size (956451, 3)\n",
      "old size (152209, 3), after removing None new size (137281, 3)\n",
      "old size (102024, 3), after removing None new size (88849, 3)\n"
     ]
    }
   ],
   "source": [
    "for split_name in splits:\n",
    "    load_path = dataset_dir + split_name + '.tsv'\n",
    "    save_path = clean_dataset_dir + split_name + '.tsv'\n",
    "    df = pd.read_csv(load_path, sep='\\t', names=['head', 'relation', 'tail'])\n",
    "    df = cleanup(df)\n",
    "    df.to_csv(save_path, index=False, sep='\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c5230-60f2-4e20-8848-89b899626d70",
   "metadata": {},
   "source": [
    "## make full supervised train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3960566-ed20-42e5-9e3d-d165f47de07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name in ['train']:\n",
    "    df = pd.read_csv(clean_dataset_dir + split_name + '.tsv', sep='\\t')\n",
    "    df.apply(triplet_to_text, axis='columns')\n",
    "    df = df.drop(columns='relation')\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.to_json(f'{modified_dataset_dir}{split_name}.json', orient='records')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8e0e4-6900-408c-bb72-77f6e81c3f41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## make modified dataset for each relation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75143b6b-bba6-4808-990c-732c0682c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name in splits:\n",
    "    df = pd.read_csv(clean_dataset_dir + split_name + '.tsv', sep='\\t')\n",
    "    for key,value in relations.items():\n",
    "        new_df = df.loc[df['relation'].isin(value)]\n",
    "        new_df.apply(triplet_to_text, axis='columns')\n",
    "        new_df = new_df.drop(columns='relation')\n",
    "        if split_name in ['test','dev']:\n",
    "            new_df = new_df.groupby('head')['tail'].apply(list).reset_index(name='tail')\n",
    "        new_df = new_df.sample(frac=1).reset_index(drop=True)\n",
    "        new_df.to_json(f'{modified_dataset_dir}{key} {split_name}.json', orient='records')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
